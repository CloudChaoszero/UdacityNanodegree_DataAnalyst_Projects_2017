{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling: Open Street Map MiniProject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modesto, Ca**\n",
    "We will observe Modesto, Ca region in [OpenStreetMap.org](https://www.openstreetmap.org) and use data munging techniques, such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity, to clean the selected OpenStreetMap data.\n",
    "\n",
    "![Modesto, CA](Images/Modesto.jpg)\n",
    "\n",
    "\n",
    "**Why we select the Modesto Region**\n",
    "\n",
    "[Modesto, Ca](https://www.openstreetmap.org/search?query=modesto%2Cca#map=12/37.6390/-120.9969) is my hometown. My motivations for using my hometown in this data wrangling procedure is to create some suggestions for Modesto related information and provide the opportunity for potential data enthusiasts from Modesto to see other natives with a passion in data.\n",
    "\n",
    "![Modesto, Ca Region](Images/modesto_map_geo.gif)\n",
    "\n",
    "**Project Outcomes:**\n",
    "\n",
    "- Assess the quality of the data for validity, accuracy, completeness, consistency and uniformity.\n",
    "- Parse and gather data from popular file formats such as .csv, .json, .xml, and .html\n",
    "- Process data from multiple files or very large files that can be cleaned programmatically.\n",
    "- Learn how to store, query, and aggregate data using MongoDB or SQL.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Notes: **\n",
    "- I will be using SQL as my data schema for this project.\n",
    "- Documentation of OpenStreetMap XLM data can be found [here](https://wiki.openstreetmap.org/wiki/OSM_XML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This project was more than just auditing street name. We had to inspect for other values. Values such as postcode, phone number, url, username, etc. However, I should have seen this coming. Confirming data integrity comes with the assumption that no values are truly valid in:\n",
    "    + original input\n",
    "    + data import\n",
    "    + data conversion\n",
    "    + and so much more\n",
    "\n",
    "- Encoding issue in audit function. I had to add <span style = \"color:red\">encoding = \"utf8\"</span> in the open() function for osm_file\n",
    "    + Turns out I was dealing with an outdated function UnicodeDictWriter. I instead implemented csv.DictReader to resolve situation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- With cleaning our data, we had to install cerberus, phonenumbers, schema, and validators libaries.\n",
    "\n",
    "- We also have to consider common analysis issues when importing data with little contributions.\n",
    "    + Because we imported data from Modesto, Ca. We had little contributions with respect to land area, compared to high populus cities like San Francisco, Ca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLICK HERE TO TOGGLE ON/OFF CODE \n",
    "&darr; &darr; &darr; &darr;  &darr; &darr; &darr; &darr;  &darr; &darr; &darr; &darr;  &darr; &darr; &darr; &darr;  &darr; &darr; &darr; &darr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "\n",
    "###XML library ElementTree\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "###Print\n",
    "import pprint\n",
    "\n",
    "###Regular expression\n",
    "import re\n",
    "\n",
    "###CSV and Dictionary \n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import codecs\n",
    "\n",
    "###Data validation\n",
    "import cerberus\n",
    "import validators\n",
    "import phonenumbers\n",
    "\n",
    "##3Schema format\n",
    "import schema_guidline\n",
    "import schema\n",
    "\n",
    "###Maths and data \n",
    "import numpy as np\n",
    "\n",
    "###String\n",
    "import string\n",
    "import schema_guidline\n",
    "\n",
    "#SQL \n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Osm File South Modesto, Ca\n",
    "south_modesto = \"south_modest_map.osm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get South Modesto Tree\n",
    "tree = ET.parse(south_modesto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get root of 'tree'\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSM Tag\n",
      "osm\n"
     ]
    }
   ],
   "source": [
    "#Check the tags for each element\n",
    "####Release 'break' to see full list of top level tags\n",
    "for event, element in ET.iterparse(south_modesto, events=(\"start\",)):\n",
    "    print(\"OSM Tag\")\n",
    "    print(element.tag)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Node Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function count_tags counts the number of top, parent, and child tags\n",
    "###parameter: OSM File\n",
    "def count_tags(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    tag_count = {}\n",
    "    \n",
    "    #Get count of all tags. If no tag is in there, add to dictionary with\n",
    "    ##Count as 1\n",
    "    for event, element in ET.iterparse(filename,events=(\"start\",)):\n",
    "        element_tag = element.tag\n",
    "        if element_tag not in tag_count:\n",
    "            tag_count[element_tag] = 1\n",
    "        else:\n",
    "            tag_count[element_tag] += 1\n",
    "            \n",
    "    return(tag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags\n",
      " {'relation': 21, 'osm': 1, 'way': 1012, 'node': 11607, 'bounds': 1, 'nd': 13760, 'tag': 6647, 'member': 2549}\n"
     ]
    }
   ],
   "source": [
    "#Implement count_tags function\n",
    "count_of_tags = count_tags(south_modesto)\n",
    "print(\"Number of tags\\n\",count_of_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Element and Tag meanings:**\n",
    "\n",
    "nd:\n",
    "\n",
    "bounds: Boundary\n",
    "\n",
    "member: \n",
    "\n",
    "way: defining linear features and area boundaries\n",
    "\n",
    "osm: OpenStreetMap\n",
    "\n",
    "node: defining points in space\n",
    "\n",
    "tag: defining specific features of map elements\n",
    "\n",
    "relation:  explain how other elements work together\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag Types and Potential Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Regular expresion lists for lower, lower_colon, and problem characters\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function key_type that has parameters element and key\n",
    "##returns key\n",
    "####Counts the element keys in tree if they are part of the three previously mentioned regular expression categories\n",
    "def key_type(element,key):\n",
    "    if element.tag ==\"tag\":\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            attrib_k = tag.attrib[\"k\"]\n",
    "            if re.search(lower,attrib_k):\n",
    "                key[\"lower\"] +=1\n",
    "            elif re.search(lower_colon,attrib_k):\n",
    "                key[\"lower_colon\"] +=1\n",
    "            \n",
    "            elif re.search(problemchars,attrib_k):\n",
    "                key[\"problemchars\"] +=1\n",
    "                \n",
    "            else:\n",
    "                key[\"other\"] += 1\n",
    "    return(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Process map function that takes in OSM file\n",
    "###Categorize element keys and place them in dictionary\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\":0,\"lower_colon\":0,\"problemchars\":0,\"other\":0}\n",
    "    #Implement key_type function for reach element's key\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        keys = key_type(element,keys)\n",
    "    return(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_processed = process_map(south_modesto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 2660, 'lower_colon': 3758, 'other': 229, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(map_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe no tag issues, as seen in the above dictionary. problemchars is 0. \n",
    "\n",
    "Should we consider looking into 'other' tags? No because the `other` tag is a tag, and not a warning to the user about the tag type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find user function that takes in OSM file\n",
    "###Return a set and list of OSM contributors, where set is the unique list\n",
    "def find_users(filename):\n",
    "    users_set = set()\n",
    "    users_list = []\n",
    "    element_osm = [\"node\",\"way\",\"relation\"]\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag == \"node\" or element.tag == \"way\" or element.tag==\"relation\":\n",
    "            for osm_el in element_osm:\n",
    "                for el in element.iter(osm_el):\n",
    "                    user_id = el.attrib[\"uid\"]\n",
    "                    \n",
    "                    users_list.append(user_id)\n",
    "                    if user_id not in users_set:\n",
    "                        users_set.add(user_id)\n",
    "                    else:\n",
    "                        pass\n",
    "    return(users_set,users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_search = find_users(south_modesto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'115918',\n",
       " '121241',\n",
       " '123633',\n",
       " '12448',\n",
       " '1249205',\n",
       " '1330847',\n",
       " '135163',\n",
       " '145231',\n",
       " '147510',\n",
       " '153669',\n",
       " '160138',\n",
       " '160949',\n",
       " '1660455',\n",
       " '1679',\n",
       " '169004',\n",
       " '1731253',\n",
       " '1734334',\n",
       " '1844075',\n",
       " '199837',\n",
       " '2012449',\n",
       " '20587',\n",
       " '207745',\n",
       " '2098497',\n",
       " '2219338',\n",
       " '2226712',\n",
       " '224610',\n",
       " '24452',\n",
       " '2511706',\n",
       " '2512300',\n",
       " '28145',\n",
       " '3057995',\n",
       " '318696',\n",
       " '339581',\n",
       " '3582',\n",
       " '360392',\n",
       " '36121',\n",
       " '371121',\n",
       " '3769434',\n",
       " '38487',\n",
       " '39504',\n",
       " '402624',\n",
       " '4535742',\n",
       " '4732',\n",
       " '5014577',\n",
       " '5201796',\n",
       " '532783',\n",
       " '55774',\n",
       " '6062872',\n",
       " '676848',\n",
       " '678132',\n",
       " '70696',\n",
       " '7168',\n",
       " '7203',\n",
       " '72235',\n",
       " '9065'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get set of OSM contributors\n",
    "user_search[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the unique set of users in the Modesto, Ca data. However, we want to know the contribution rate of some user, and what the top contributor is?\n",
    "\n",
    "\n",
    "Below is a function for computing the stats of top contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#user_stats function takes in a list of users(user_search[1])\n",
    "###outputs total contribution, contribution rate, mean, mean of contribution rate\n",
    "### standard deviation, and standard deviation of rate of contributions, in order.\n",
    "def user_stats(user_list):\n",
    "    #Make set of users\n",
    "    users_unique = set(user_list)\n",
    "    #Dictionary count\n",
    "    user_contribution_count = {}\n",
    "    #Count of contributions\n",
    "    total_contributions = 0\n",
    "    stdev = None\n",
    "    \n",
    "    contribution_rate = {}\n",
    "    \n",
    "    #Calculate count per user\n",
    "    for user in user_list:\n",
    "        if user not in user_contribution_count:\n",
    "            user_contribution_count[user] = 1\n",
    "        else:\n",
    "            user_contribution_count[user] +=1\n",
    "    #calculate total count        \n",
    "    for key, value in user_contribution_count.items():\n",
    "        total_contributions +=value\n",
    "    #Contribution rate     \n",
    "    for key, value in user_contribution_count.items():\n",
    "        contribution_rate[key] = value / total_contributions\n",
    "    #Get mean of contributions and rate of contributions    \n",
    "    mean_val = np.mean(list(user_contribution_count.values() ) )\n",
    "    mean_val_rate = np.mean(list(contribution_rate.values() ) )\n",
    "    \n",
    "    #Get std.dev of contributions and rate of contributions \n",
    "    stdev_val = np.std(list(user_contribution_count.values() ) )\n",
    "    stdev_val_rate =  np.std(list(contribution_rate.values() ) )\n",
    "    \n",
    "    return(total_contributions,contribution_rate,mean_val,mean_val_rate ,stdev_val,stdev_val_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_statistics = user_stats(user_search[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contribution rate\n",
      "{'115918': 0.00031645569620253165,\n",
      " '121241': 0.0060917721518987345,\n",
      " '123633': 0.0005537974683544304,\n",
      " '12448': 0.0007120253164556962,\n",
      " '1249205': 0.00039556962025316455,\n",
      " '1330847': 0.03884493670886076,\n",
      " '135163': 0.002610759493670886,\n",
      " '145231': 7.911392405063291e-05,\n",
      " '147510': 0.17753164556962026,\n",
      " '153669': 0.03449367088607595,\n",
      " '160138': 0.0038765822784810125,\n",
      " '160949': 0.011629746835443038,\n",
      " '1660455': 7.911392405063291e-05,\n",
      " '1679': 0.0005537974683544304,\n",
      " '169004': 0.00031645569620253165,\n",
      " '1731253': 7.911392405063291e-05,\n",
      " '1734334': 0.08109177215189874,\n",
      " '1844075': 0.0015822784810126582,\n",
      " '199837': 0.0022943037974683545,\n",
      " '2012449': 0.0015822784810126582,\n",
      " '20587': 0.0046677215189873415,\n",
      " '207745': 0.010996835443037974,\n",
      " '2098497': 7.911392405063291e-05,\n",
      " '2219338': 0.011471518987341773,\n",
      " '2226712': 0.005379746835443038,\n",
      " '224610': 0.00015822784810126583,\n",
      " '24452': 0.010284810126582278,\n",
      " '2511706': 0.003639240506329114,\n",
      " '2512300': 0.00023734177215189873,\n",
      " '28145': 7.911392405063291e-05,\n",
      " '3057995': 0.00015822784810126583,\n",
      " '318696': 0.00047468354430379745,\n",
      " '339581': 0.00047468354430379745,\n",
      " '3582': 7.911392405063291e-05,\n",
      " '360392': 0.0007120253164556962,\n",
      " '36121': 0.05300632911392405,\n",
      " '371121': 0.0011075949367088608,\n",
      " '3769434': 7.911392405063291e-05,\n",
      " '38487': 7.911392405063291e-05,\n",
      " '39504': 0.00031645569620253165,\n",
      " '402624': 0.017246835443037976,\n",
      " '4535742': 7.911392405063291e-05,\n",
      " '4732': 0.0012658227848101266,\n",
      " '5014577': 7.911392405063291e-05,\n",
      " '5201796': 0.004905063291139241,\n",
      " '532783': 0.22270569620253164,\n",
      " '55774': 0.22349683544303797,\n",
      " '6062872': 0.002056962025316456,\n",
      " '676848': 0.00015822784810126583,\n",
      " '678132': 0.0014240506329113924,\n",
      " '70696': 0.00031645569620253165,\n",
      " '7168': 0.000870253164556962,\n",
      " '7203': 0.00015822784810126583,\n",
      " '72235': 0.0007911392405063291,\n",
      " '9065': 0.05625}\n"
     ]
    }
   ],
   "source": [
    "#Contribution rate\n",
    "print(\"Contribution rate\")\n",
    "pprint.pprint(user_statistics[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Highest Contributor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most contributions from User: 55774 \n",
      "with a total contribution rate of: 0.22349683544303797\n"
     ]
    }
   ],
   "source": [
    "max_user = None\n",
    "max_user_value = 0\n",
    "for key,value in user_statistics[1].items():\n",
    "    if value >max_user_value:\n",
    "        max_user_value = value\n",
    "        max_user = key\n",
    "print(\"Most contributions from User:\",max_user,\"\\nwith a total contribution rate of:\",max_user_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of Contributions\n",
      "229.818181818 \n",
      "\n",
      "Total count of Contributions\n",
      "12640 \n",
      "\n",
      "Average rate of Contributions\n",
      "0.0181818181818 \n",
      "\n",
      "Standard deviation of Contributions\n",
      "612.377485808 \n",
      "\n",
      "Standard deviation of the rate of Contributions\n",
      "0.0484475859025 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Average number of contributions\n",
    "print(\"Average number of Contributions\")\n",
    "print(user_statistics[2],\"\\n\")\n",
    "\n",
    "#Total count of contributions\n",
    "print(\"Total count of Contributions\")\n",
    "print(user_statistics[0],\"\\n\")\n",
    "\n",
    "#average rate of contributions\n",
    "print(\"Average rate of Contributions\")\n",
    "print(user_statistics[3],\"\\n\")\n",
    "\n",
    "#Stdev of number of contributions\n",
    "print(\"Standard deviation of Contributions\")\n",
    "print(user_statistics[4],\"\\n\")\n",
    "\n",
    "#Stdev of rate of contributions\n",
    "print(\"Standard deviation of the rate of Contributions\")\n",
    "print(user_statistics[5],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determine the integrity of our data. We look into the street key and values entries to determine if they are correctly entered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular expression for street type for ignoring b,repitition of S, and some other character with 0 or 1 repititions\n",
    "\n",
    "street_type_re = re.compile(r'St\\.|St{2,}|Rd|Rd.|Ave{3,}', re.IGNORECASE)\n",
    "#Expected street spelling list\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "#Map street abbr. to actual word\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\", \"Ave\":\"Avenue\",\"Rd\":\"Road\"\n",
    "            }\n",
    "\n",
    "mapping_abbrev = { 'W ': 'West ', 'S ': 'South ', 'N ': 'North ', 'E ': 'East ',\n",
    "                   'W. ': 'West ', 'S. ': 'South', 'N. ': 'North ', 'E. ': 'East '\n",
    "                 }\n",
    "mapping_zipcodes = ['95356','95307','95358']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create audit_street_type function with parameters street_types,street_name\n",
    "## to obtain mispelled streets\n",
    "def audit_street_type(street_types,street_name):\n",
    "    street_name = street_name.strip(\"{\")\n",
    "    street_name = street_name.strip(\"}\")\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type] = (street_name)\n",
    "#identify street in element's key\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#audit function that takes in osm file\n",
    "def audit(osmfile):\n",
    "    #Read in osmfile\n",
    "    osm_file = open(osmfile,'r',encoding=\"utf-8\")\n",
    "    #Create empty defaultdict \n",
    "    street_types = defaultdict(set)\n",
    "    \n",
    "    #go through each element in osm file. If it is a node or a tag, and has child tags, then\n",
    "    ##we audit the street type and tag attribute v\n",
    "    for event, element in ET.iterparse(osm_file,events =(\"start\",) ):\n",
    "        if element.tag == \"node\" or element.tag==\"way\":\n",
    "            for tag in element.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return(street_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'Rd': 'Crows Landing Rd #7'})\n"
     ]
    }
   ],
   "source": [
    "st_types = audit(south_modesto)\n",
    "print(st_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rd': 'Crows Landing Rd #7'}\n"
     ]
    }
   ],
   "source": [
    "dict_st_stypes = dict(st_types)\n",
    "print(dict_st_stypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the only issue street name is  \"Crows landing Rd,\" instead of \"Crows landing Road.\"\n",
    "\n",
    "In these next steps, we aim to fix any street names that are not properly spelled/unabbreviated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Street Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function update_name that has parameters name and mapping\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        #If the name exist in mapping keys, it means that's a problem and we should fix it.\n",
    "        if street_type in mapping.keys():\n",
    "            name = re.sub(street_type, mapping[street_type], name)\n",
    "    return(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crows Landing Rd #7\n"
     ]
    }
   ],
   "source": [
    "#For every way in st_types\n",
    "for st_type, ways in st_types.items():\n",
    "    #For every name in way\n",
    "    print(ways)\n",
    "    better_name = update_name(ways, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Crows Landing Road #7'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crows Landing Rd #7\n",
      "Turned into\n",
      "Crows Landing Road #7\n"
     ]
    }
   ],
   "source": [
    "for event, element in ET.iterparse(south_modesto, events=(\"start\",)):\n",
    "    for tag in element.iter(\"tag\"):\n",
    "        if(tag.attrib['k']==\"addr:street\"):\n",
    "            for key, val in st_types.items():\n",
    "                if tag.attrib['v'] == val:\n",
    "                    print(tag.attrib['v'])\n",
    "                    tag.attrib['v'] = better_name\n",
    "                    print(\"Turned into\")\n",
    "                    print(tag.attrib['v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v': 'motorway_junction', 'k': 'highway'}\n",
      "{'v': '222', 'k': 'ref'}\n",
      "{'v': 'stop', 'k': 'highway'}\n",
      "{'v': 'motorway_junction', 'k': 'highway'}\n",
      "{'v': '221', 'k': 'ref'}\n",
      "{'v': 'motorway_junction', 'k': 'highway'}\n",
      "{'v': 'yes', 'k': 'noref'}\n",
      "{'v': 'motorway_junction', 'k': 'highway'}\n",
      "{'v': '222', 'k': 'ref'}\n",
      "{'v': 'motorway_junction', 'k': 'highway'}\n",
      "{'v': '223', 'k': 'ref'}\n",
      "{'v': 'motorway_junction', 'k': 'highway'}\n",
      "{'v': '220', 'k': 'ref'}\n"
     ]
    }
   ],
   "source": [
    "#Print out the first 10 tags \n",
    "##If you want to print out more, take off break portion\n",
    "i = 0\n",
    "for event, element in ET.iterparse(south_modesto, events=(\"start\",)):\n",
    "    #----Break area-----\n",
    "    i+=1\n",
    "    if i ==10:\n",
    "        break\n",
    "    #----------------\n",
    "    #Print tag of elements\n",
    "    for tag in element.iter(\"tag\"):\n",
    "        print(tag.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing 'v' and 'k' tags within each element, we see that Street Types are not our only concern. I.e., We need to inspect other features in our data to determine data integrity.\n",
    "\n",
    "We audit for phone, state, zipcode, and website address features in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Audit state type\n",
    "state_types = []\n",
    "def audit_state_type(state_types,state):\n",
    "    if len(state) !=2:\n",
    "        state_types.append(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipcode_types = []\n",
    "def audit_zipcode_type(zipcode_types,zipcode):\n",
    "    if len(zipcode) != 5:\n",
    "        zipcode_types.append(zipcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housenumber_type_re = re.compile(r'^\\d+(-?\\d)*$')\n",
    "\n",
    "housephone_number_types = defaultdict(int)\n",
    "\n",
    "#Audit housephone values\n",
    "def audit_housephone(housephone_number_types, number):\n",
    "    m = housenumber_type_re.search(number)\n",
    "    if not m:\n",
    "        housephone_number_types.append(number)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phone_number_types = defaultdict(set)\n",
    "\n",
    "#Audit phone entires. We use phonenumbers library to verify #'s\n",
    "def audit_phone(phone_number_types,number):\n",
    "    if number.startswith(\"+\"):\n",
    "        number = number[1:]\n",
    "    z = phonenumbers.parse(number,\"US\")\n",
    "    v = phonenumbers.is_possible_number(z)\n",
    "    if not v:\n",
    "        phone_number_types.append(number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audit website values. We use validators to confirm url entry\n",
    "website_types = defaultdict(set)\n",
    "def audit_website(website_types,website):\n",
    "    if not website.startswith('http'):\n",
    "        website = 'http://' + website\n",
    "    if not validators.url(website):\n",
    "        website_types.append(website)\n",
    "        \n",
    "def update_state(state, state_list):\n",
    "    if state in state_list:\n",
    "        state = \"CA\"\n",
    "    return(state)\n",
    "\n",
    "\n",
    "#postcode_type_re = re.compile(r'[0-9]+')\n",
    "def update_postcode(postcode_types):\n",
    "    if type(postcode_types) is type([]):\n",
    "        pc_list = []\n",
    "        for postcode in postcode_types:\n",
    "            pc_list.append(postcode.split(\" \")[1])\n",
    "\n",
    "            return(pc_list)\n",
    "    elif type(postcode_types) is type(''):\n",
    "        if len(postcode_types) !=5:\n",
    "            postcode = postcode_types.split(\" \")\n",
    "            return(postcode[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check if some condition\n",
    "\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def is_state(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:state\" or elem.attrib['k'] == \"is_in:state_code\")\n",
    "\n",
    "def is_postcode(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def is_housenumber(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:housenumber\")\n",
    "\n",
    "def is_phone(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == 'phone')\n",
    "\n",
    "def is_website(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"website\" or elem.attrib['k'] == \"url\" or \\\n",
    "                                    (elem.attrib['k'] == \"source\" and elem.attrib['v'].startswith(\"http\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Types: \n",
      "[]\n",
      "PostCode Types: \n",
      "['CA 95351', 'CA 95351', 'CA 95351', 'CA 95351', 'CA 95351', 'CA 95351']\n",
      "Problematic House Numbers: \n",
      "defaultdict(<class 'int'>, {})\n",
      "Problematic Phone Numbers: \n",
      "defaultdict(<class 'set'>, {})\n",
      "Problematic Website addresses: \n",
      "defaultdict(<class 'set'>, {})\n"
     ]
    }
   ],
   "source": [
    "def printer(type_of):\n",
    "    pprint.pprint(type_of)\n",
    "\n",
    "#Additional audits for several variables, all in one. \n",
    "def audit_additional(file):\n",
    "    for event, elem in ET.iterparse(file):\n",
    "        if is_state(elem):\n",
    "            audit_state_type(state_types, elem.attrib['v'])\n",
    "        elif is_postcode(elem):\n",
    "            audit_zipcode_type(zipcode_types, elem.attrib['v'])\n",
    "        elif is_housenumber(elem):\n",
    "            audit_housephone(housephone_number_types, elem.attrib['v'])\n",
    "        elif is_phone(elem):\n",
    "            audit_phone(phone_number_types, elem.attrib['v'])\n",
    "        elif is_website(elem):\n",
    "            audit_website(website_types, elem.attrib['v'])\n",
    "\n",
    "    print(\"State Types: \")\n",
    "    printer(state_types)\n",
    "    \n",
    "    print(\"PostCode Types: \")\n",
    "    printer(zipcode_types)\n",
    "    \n",
    "    print(\"Problematic House Numbers: \")\n",
    "    printer(housephone_number_types)\n",
    "    \n",
    "    print(\"Problematic Phone Numbers: \")\n",
    "    printer(phone_number_types)\n",
    "    print(\"Problematic Website addresses: \")\n",
    "    printer(website_types)\n",
    "\n",
    "    \n",
    "audit_additional(south_modesto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe there aren't any issues with the additional values. Though this osm file is small, we can anticipate a lower frequency of errors/issues occuring within our data.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "In our 50+MB Modesto, Ca OSM File, we shoul anticipate more errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CA 95351', 'CA 95351', 'CA 95351', 'CA 95351', 'CA 95351', 'CA 95351']\n",
      "Corrected to\n",
      "['95351']\n"
     ]
    }
   ],
   "source": [
    "printer(zipcode_types)\n",
    "print(\"Corrected to\")\n",
    "print(update_postcode(zipcode_types) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe no incorrect information was typed into the Phone Number, Website, and House Number, State values. This is good! We continue to converting our osm data into csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "NODES_PATH = \"Output-Files/nodes.csv\"\n",
    "NODE_TAGS_PATH = \"Output-Files/nodes_tags.csv\"\n",
    "WAYS_PATH = \"Output-Files/ways.csv\"\n",
    "WAY_NODES_PATH = \"Output-Files/ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"Output-Files/ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema_guidline.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_in_postcode_re = re.compile(r'^([A-Z]){2}\\s{1}', re.IGNORECASE)\n",
    "    #Clean and shape node or way XML element to a dictionary\n",
    "\n",
    "#shape_element function with parameters:\n",
    "###element, node_attr_fields,way_attr_fields,problem_chars,default_tag_type\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    \n",
    "    #If the top tag is node we then collect the node attributes and tags\n",
    "    if element.tag == 'node':\n",
    "        #for every attribute in element\n",
    "        for attr in element.attrib:\n",
    "            #and the attribute is in NODE_FIELDS\n",
    "            if attr in NODE_FIELDS:\n",
    "                #Collect the attributes into node_attrib dictionary\n",
    "                node_attribs[attr] = element.attrib[attr]\n",
    "        #for the child in element        \n",
    "        for child in element:\n",
    "            fill_in_dict = {}\n",
    "            #If any character from the \"k\" attribute in LOWER_COLON\n",
    "            if LOWER_COLON.match(child.attrib[\"k\"]):\n",
    "                #Store values in fill_in_dict\n",
    "                fill_in_dict[\"type\"] = child.attrib[\"k\"].split(\":\")[0]\n",
    "                fill_in_dict[\"key\"] = child.attrib[\"k\"].split(\":\")[1]\n",
    "                fill_in_dict[\"id\"] = element.attrib[\"id\"]\n",
    "                if is_street_name(child):\n",
    "                    fill_in_dict[\"value\"] = update_name(child.attrib[\"v\"],mapping)\n",
    "                else:\n",
    "                    fill_in_dict[\"value\"] = child.attrib[\"v\"]\n",
    "                tags.append(fill_in_dict)\n",
    "            #Ignore \"k\" attribute value if it is a PROBLEMCHARS\n",
    "            elif PROBLEMCHARS.match(child.attrib[\"k\"]):\n",
    "                continue\n",
    "            #If anything else, just save the \"k\" attribute's values\n",
    "            else:\n",
    "                fill_in_dict[\"type\"] =default_tag_type\n",
    "                if(is_postcode(child)):\n",
    "                    fill_in_dict['value'] = update_postcode(child.attrib['k'])\n",
    "                else:\n",
    "                    fill_in_dict[\"key\"] = child.attrib['k']\n",
    "                fill_in_dict[\"id\"] = element.attrib['id']\n",
    "                fill_in_dict[\"value\"] = child.attrib['v']\n",
    "                tags.append(fill_in_dict)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    #If the top element tag is \"way\"    \n",
    "    elif element.tag ==\"way\":\n",
    "        #For every attribute in element\n",
    "        for attrib in element.attrib:\n",
    "            #and the attribute is in \"WAY_FIELDS\"\n",
    "            if attrib in WAY_FIELDS:\n",
    "                #Store the attribute in element attribute\n",
    "                way_attribs[attrib] = element.attrib[attrib]\n",
    "        #Let position be 0\n",
    "        position = 0\n",
    "        \n",
    "        #For every child in element\n",
    "        for child in element:\n",
    "            way_tag = {}\n",
    "            way_node = {}\n",
    "            #If the child is a tag\n",
    "            if child.tag == 'tag':\n",
    "                \n",
    "                #If the child attribute \"k\" matched any item in LOWER_COLON\n",
    "                if LOWER_COLON.match(child.attrib['k']):\n",
    "                    #Store the chil attribute values\n",
    "                    \n",
    "                    \n",
    "                    way_tag['type'] = child.attrib['k'].split(':',1)[0] #Get first part of K value\n",
    "                    way_tag['key'] = child.attrib['k'].split(':',1)[1] #get second part of k value\n",
    "                    way_tag['id'] = element.attrib['id'] #get id\n",
    "                    if(is_street_name(child)):\n",
    "                        way_tag['value'] = update_name(child.attrib['v'],mapping) #get value 'v'\n",
    "                    else:\n",
    "                        way_tag['value'] = child.attrib['v'] \n",
    "                    tags.append(way_tag) #save way_tag dictiionary\n",
    "                #Ignore weird \"k\" values in the child's attribute\n",
    "                elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                    continue\n",
    "                #If the child's attribute \"k\" is anything else, just save value\n",
    "                else:\n",
    "                    way_tag['type'] = 'regular'\n",
    "                    if(is_postcode(child)):\n",
    "                        way_tag['key'] = update_postcode(child.attrib['k'])\n",
    "                    else:\n",
    "                         way_tag['key'] = child.attrib['k']\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = child.attrib['v']\n",
    "                    tags.append(way_tag)\n",
    "            #If the child's tag is \"nd\", store values\n",
    "            elif child.tag == 'nd':\n",
    "                way_node['id'] = element.attrib['id']\n",
    "                way_node['node_id'] = child.attrib['ref']\n",
    "                way_node['position'] = position\n",
    "                position += 1\n",
    "                way_nodes.append(way_node)\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "                \n",
    "        #Write out csv documents\n",
    "        nodes_writer = csv.DictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = csv.DictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = csv.DictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = csv.DictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = csv.DictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "        \n",
    "        #write a header to respective documents\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "        \n",
    "        #data integrity validation\n",
    "        \n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            '''\n",
    "            if element.tag == \"node\":\n",
    "                continue\n",
    "            elif element.tag == \"way\":\n",
    "                \n",
    "                print(el['way_nodes'])\n",
    "                print(el['way_tags'])\n",
    "            '''\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(south_modesto, validate=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefit and costs of updating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Tampered with raw data\n",
    "- Potentially could have induced bias into our data\n",
    "- Typing errors in data cleaning process\n",
    "- and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Insights through SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We intiate light analysis through SQLite3.\n",
    "\n",
    "In this next stage, we aim to create a database <span style =\"color:green\">openstreemap.db</span>. In this database, we have five tables. These five tables are:\n",
    "\n",
    "- nodes\n",
    "- nodes_tags\n",
    "- ways\n",
    "- ways_tags\n",
    "- ways_nodes\n",
    "\n",
    "Below is the schema for the above tables\n",
    "\n",
    "[SQL Schema](https://gist.github.com/swwelch/f1144229848b407e0a5d13fcb7fbbd6f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = sqlite3.connect(\"Database/openstreetmap.db\")\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x193001b58f0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_nodes_table = '''\n",
    "CREATE TABLE nodes (\n",
    "id  INTEGER PRIMARY KEY NOT NULL,\n",
    "lat REAL,\n",
    "lon REAL,\n",
    "user TEXT,\n",
    "uid INTEGER,\n",
    "version INTEGER,\n",
    "changeset INTEGER,\n",
    "timestamp TEXT\n",
    ");'''\n",
    "cursor.execute(create_nodes_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(NODES_PATH,'r') as source:\n",
    "    diction = csv.DictReader(source)\n",
    "    insert_query_nodes = '''INSERT INTO nodes(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);'''\n",
    "    write_into_nodes = [(i['id'], i['lat'],i['lon'], i['user'], i['uid'], i['version'], i['changeset'], i['timestamp']) for i in diction]\n",
    "    \n",
    "cursor.executemany(insert_query_nodes, write_into_nodes)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(92655337,), (92655341,)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT id FROM nodes LIMIT 2;\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes_Tags Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x193001b58f0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_nodes_tags_table = '''\n",
    "CREATE TABLE nodes_tags(\n",
    "id INTEGER references nodes(id),\n",
    "key TEXT,\n",
    "value TEXT,\n",
    "type TEXT\n",
    "                                \n",
    ");'''\n",
    "cursor.execute(create_nodes_tags_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(NODE_TAGS_PATH,'r') as source2:\n",
    "    diction2 = csv.DictReader(source2)\n",
    "    insert_query_nodes_tags = '''INSERT INTO nodes_tags(id, key, value, type) VALUES (?,?,?,?);'''\n",
    "    write_into_nodes_tags = [(i['id'], i['key'], i['value'], i['type']) for i in diction2]\n",
    "cursor.executemany(insert_query_nodes_tags,write_into_nodes_tags)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(92655688,), (92655688,)]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT id FROM nodes_tags LIMIT 2;\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x193001b58f0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_ways_table = '''\n",
    "CREATE TABLE ways(\n",
    "id INTEGER PRIMARY KEY NOT NULL,\n",
    "user TEXT,\n",
    "uid INTEGER,\n",
    "version TEXT,\n",
    "changeset INTEGER,\n",
    "timestamp TEXT\n",
    ");'''\n",
    "cursor.execute(create_ways_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x193001b58f0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(WAYS_PATH,'r') as source3:\n",
    "    diction3 = csv.DictReader(source3)\n",
    "    insert_query_ways = '''INSERT INTO ways(id,user,uid,version,changeset,timestamp) VALUES(?,?,?,?,?,?);'''\n",
    "    write_into_ways = [(i['id'],i['user'],i['uid'],i['version'],i['changeset'],i['timestamp']) for i in diction3]\n",
    "cursor.executemany(insert_query_ways,write_into_ways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10598597, 'TheDutchMan13', 1330847, '3', 49373876, '2017-06-08T17:17:44Z'),\n",
      " (10598615, 'TheDutchMan13', 1330847, '3', 49373876, '2017-06-08T17:17:45Z')]\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT * FROM ways LIMIT 2'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways_Tags Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x193001b58f0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_ways_tags_table = '''\n",
    "CREATE TABLE ways_tags(\n",
    "id INTEGER NOT NULL,\n",
    "key TEXT NOT NULL,\n",
    "value TEXT NOT NULL,\n",
    "type TEXT,\n",
    "FOREIGN KEY (id) REFERENCES ways(id)\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_ways_tags_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x193001b58f0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(WAY_TAGS_PATH,'r') as source4:\n",
    "    diction4 = csv.DictReader(source4)\n",
    "    insert_query_ways_tags = '''INSERT INTO ways_tags(id,key,value,type) VALUES(?,?,?,?);'''\n",
    "    write_into_ways_tags = [(i['id'],i['key'],i['value'],i['type']) for i in diction4]\n",
    "cursor.executemany(insert_query_ways_tags,write_into_ways_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10598597, 'highway', 'residential', 'regular'),\n",
      " (10598597, 'name', 'Crescent Moon Court', 'regular')]\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT * FROM ways_tags LIMIT 2'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ways Nodes Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x193001b58f0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_ways_nodes_table = '''\n",
    "CREATE TABLE ways_nodes(\n",
    "id INTEGER NOT NULL,\n",
    "node_id INTEGER NOT NULL,\n",
    "position INTEGER NOT NULL,\n",
    "FOREIGN KEY (id) REFERENCES ways(id)\n",
    "FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    "\n",
    ");'''\n",
    "cursor.execute(create_ways_nodes_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x193001b58f0>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(WAY_NODES_PATH,'r') as source5:\n",
    "    diction5 = csv.DictReader(source5)\n",
    "    insert_query_ways_nodes = '''INSERT INTO ways_nodes(id,node_id,position) VALUES(?,?,?);'''\n",
    "    write_into_ways_nodes = [(i['id'],i['node_id'],i['position']) for i in diction5]\n",
    "cursor.executemany(insert_query_ways_nodes,write_into_ways_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10598597, 92655337, 0), (10598597, 92655341, 1)]\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT * FROM ways_nodes LIMIT 2;'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Questions from our OpenStreetMap Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Contributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(55774, 'nmixter', 2800),\n",
      " (532783, 'Eureka gold', 2771),\n",
      " (147510, 'woodpeck_fixbot', 2244),\n",
      " (1734334, 'Field Enterprise', 889),\n",
      " (9065, 'brianboru', 711),\n",
      " (36121, 'Chris Lawrence', 670),\n",
      " (153669, 'dchiles', 372),\n",
      " (402624, 'bdiscoe', 215),\n",
      " (160949, 'eric22', 139),\n",
      " (207745, 'NE2', 131),\n",
      " (24452, 'Speight', 130),\n",
      " (2219338, 'RichRico', 97),\n",
      " (121241, 'zephyr', 76),\n",
      " (2226712, 'dannykath', 58),\n",
      " (5201796, 'LukeSkydragon', 49),\n",
      " (160138, 'DanHomerick', 46),\n",
      " (2511706, 'calfarome', 33),\n",
      " (135163, 'MikeN', 29),\n",
      " (6062872, 'frankyakapancho', 22),\n",
      " (1844075, 'jgcampos1', 18),\n",
      " (4732, 'iandees', 16),\n",
      " (199837, 'happy5214', 14),\n",
      " (371121, 'AndrewSnow', 14),\n",
      " (2012449, 'Dami_Tn', 13),\n",
      " (72235, 'Basstoelpel', 10),\n",
      " (123633, 'stevea', 6),\n",
      " (360392, 'maxerickson', 5),\n",
      " (1679, 'andrewpmk', 4),\n",
      " (115918, 'Timothy Smith', 4),\n",
      " (169004, 'oldtopos', 3),\n",
      " (2512300, 'samely', 3),\n",
      " (7203, 'ToffeHoff', 2),\n",
      " (676848, 'jdcard', 2),\n",
      " (1249205, 'Rudolf Mayer', 2),\n",
      " (3057995, 'oini', 2),\n",
      " (3582, 'davidearl', 1),\n",
      " (28145, 'amillar', 1),\n",
      " (145231, 'woodpeck_repair', 1),\n",
      " (1660455, 'juergenb22', 1),\n",
      " (1731253, 'keepright! ler', 1),\n",
      " (2098497, 'me0', 1),\n",
      " (4535742, 'sierrawestern', 1)]\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT uid, user, COUNT(uid) FROM nodes GROUP BY uid ORDER BY COUNT(uid) DESC;'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalling the most contributing statistic from our python code, we confirm that user <span style=\"color:red\">55774, nmixter,</span> was the user that contributed most to South Modesto Map entries\n",
    "\n",
    "nmixter's contribution ratio was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.241233738261394 percent\n"
     ]
    }
   ],
   "source": [
    "print(2800/11607,\"percent\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the fact that the total OpenStreetMap South Modesto entries was 11607, as seem below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1679.0,)\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT AVG(uid) FROM nodes GROUP BY uid;'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Contributor nmixter's track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What locations did nmixter contribute to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(37.5838301, -120.9936185),\n",
      " (37.5838529, -120.9927497),\n",
      " (37.5827002, -120.9922406),\n",
      " (37.5813487, -120.9905012),\n",
      " (37.5812047, -120.9892393)]\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT lat, lon FROM nodes WHERE user = 'nmixter' LIMIT 5;'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was curious who the user nmixter was. So, I found his profile on OpenStreetMap. In [Nmixter's Contributions](https://www.openstreetmap.org/changeset/45641632#map=9/37.3582/-120.7040), we observe that we has made 10,000+ entries over the course of being on OSM. \n",
    "\n",
    "His Modesto contributions were made four months ago, and he still continues to expand out into California. I.e., Nmixter may be no Modesto native, but just a high contributor on OSM.\n",
    "![OSM](Images/nmixter_modesto_osm_1.JPG)\n",
    "\n",
    "$ $\n",
    "\n",
    "Now, let's continue to the nodes_tags table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Tags Table Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying Street names from previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(358778796, 'street', '6th Street', 'addr'),\n",
      " (358778832, 'street', 'Lawrence Street', 'addr'),\n",
      " (3466886624, 'street', 'Lawrence Street', 'addr'),\n",
      " (4210901375, 'street', 'Lawrence Street', 'addr'),\n",
      " (4386766919, 'street', 'Crows Landing Road #7', 'addr')]\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT * FROM nodes_tags WHERE key = 'street';'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the last street name in the array, we observe \"Crows Landing Rd #7\" being corrected and exported as \"Crows Landing Road #7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(358778796, 'postcode', '95307', 'addr'),\n",
      " (358778832, 'postcode', '95307', 'addr'),\n",
      " (3466886624, 'postcode', '95307', 'addr'),\n",
      " (4210901375, 'postcode', '95307', 'addr'),\n",
      " (4386766919, 'postcode', '95358', 'addr')]\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT * FROM nodes_tags WHERE key = 'postcode';'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we observe no state abbreviation \"CA\" within any of the postcodes(third item of each list element) was factored into our export file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Discoveries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('highway',),\n",
      " ('ref',),\n",
      " ('noref',),\n",
      " ('railway',),\n",
      " ('stop',),\n",
      " ('ele',),\n",
      " ('gnis:Class',),\n",
      " ('gnis:County',),\n",
      " ('gnis:County_num',),\n",
      " ('id',),\n",
      " ('gnis:ST_alpha',),\n",
      " ('gnis:ST_num',),\n",
      " ('import_uuid',),\n",
      " ('is_in',),\n",
      " ('name',),\n",
      " ('place',),\n",
      " ('population',),\n",
      " ('wikipedia',),\n",
      " ('county_id',),\n",
      " ('created',),\n",
      " ('feature_id',),\n",
      " ('state_id',),\n",
      " ('leisure',),\n",
      " ('amenity',),\n",
      " ('city',),\n",
      " ('housenumber',),\n",
      " ('postcode',),\n",
      " ('state',),\n",
      " ('street',),\n",
      " ('operator',),\n",
      " ('man_made',),\n",
      " ('power',),\n",
      " ('county_name',),\n",
      " ('reviewed',),\n",
      " ('source',),\n",
      " ('traffic_signals',),\n",
      " ('tourism',),\n",
      " ('landuse',),\n",
      " ('shop',),\n",
      " ('cuisine',),\n",
      " ('opening_hours',),\n",
      " ('phone',),\n",
      " ('smoking',),\n",
      " ('owner',),\n",
      " ('website',),\n",
      " ('sport',)]\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT DISTINCT(key) FROM nodes_tags;'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the types of keys from the nodes_tags table. These keys allow us to observe the listed attributes/descriptions of the South Modesto region.\n",
    "\n",
    "For example, below is the list of highways in the Sout Modesto region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(92655688, 'highway', 'motorway_junction', 'regular'),\n",
      " (92655857, 'highway', 'stop', 'regular'),\n",
      " (92655883, 'highway', 'motorway_junction', 'regular'),\n",
      " (92656952, 'highway', 'motorway_junction', 'regular'),\n",
      " (92657747, 'highway', 'motorway_junction', 'regular'),\n",
      " (92657978, 'highway', 'motorway_junction', 'regular'),\n",
      " (92658163, 'highway', 'motorway_junction', 'regular'),\n",
      " (92687725, 'highway', 'stop', 'regular'),\n",
      " (92699960, 'highway', 'turning_circle', 'regular'),\n",
      " (92704729, 'highway', 'turning_circle', 'regular'),\n",
      " (92722566, 'highway', 'turning_circle', 'regular'),\n",
      " (92723111, 'highway', 'turning_circle', 'regular'),\n",
      " (92726529, 'highway', 'motorway_junction', 'regular'),\n",
      " (92737991, 'highway', 'turning_circle', 'regular'),\n",
      " (394497566, 'highway', 'motorway_junction', 'regular'),\n",
      " (1962196839, 'highway', 'traffic_signals', 'regular'),\n",
      " (2639832777, 'highway', 'turning_circle', 'regular'),\n",
      " (2639832830, 'highway', 'turning_circle', 'regular'),\n",
      " (2642482262, 'highway', 'turning_circle', 'regular'),\n",
      " (2642482264, 'highway', 'stop', 'regular'),\n",
      " (2642482277, 'highway', 'turning_circle', 'regular'),\n",
      " (2642482283, 'highway', 'turning_circle', 'regular'),\n",
      " (2642482290, 'highway', 'turning_circle', 'regular'),\n",
      " (3563870419, 'highway', 'stop', 'regular'),\n",
      " (4697921152, 'highway', 'traffic_signals', 'regular'),\n",
      " (4697921156, 'highway', 'traffic_signals', 'regular'),\n",
      " (4697921163, 'highway', 'traffic_signals', 'regular')]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM nodes_tags WHERE key ='highway'\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and below is the sport key(s) associated with our nodes_tags table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4881001396, 'sport', 'basketball', 'regular')]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM nodes_tags WHERE key ='sport'\"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's weird how there is only one sport, namely basketball. I assume this value implies an OSM user indicated a basketball court was in South Modesto. \n",
    "\n",
    "\n",
    "(I also want to see this recorded node because **ball is life**)\n",
    "\n",
    "$ $ \n",
    "\n",
    "Let's see the location(latitude,longitude) of this 'basketball' value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where is that basketball court?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4881001396,\n",
      "  37.5831236,\n",
      "  -120.9817495,\n",
      "  'frankyakapancho',\n",
      "  6062872,\n",
      "  1,\n",
      "  49036064,\n",
      "  '2017-05-28T02:06:02Z',\n",
      "  4881001396,\n",
      "  'sport',\n",
      "  'basketball',\n",
      "  'regular')]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM nodes JOIN nodes_tags ON nodes.id = nodes_tags.id WHERE nodes_tags.value = 'basketball' \"\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, We observe user <span style=\"color:red\">frankyakapancho</span> created this basketball value on node located at (37.5831236,-120.9817495). \n",
    "\n",
    "I google mapped these coordinates, and found that this node was located in Ceres, Ca.\n",
    "\n",
    "![Basketball Tag](Images/nodes_tags_value_basketball.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not zoom in even more? That is, we can utilize Google Map's street view mode to see what this basketball court looks like.\n",
    "\n",
    "![I used to run here](Images/nodes_tags_value_basketball_visual.JPG)\n",
    "\n",
    "\n",
    "**WHOA!**, I used to cross this park during my long distance runs. My mom actually lives near this park. Honestly, I was shocked to see this park. Unfortunately, we could not see the park. It's to the left of this image.\n",
    "\n",
    "But what is more amazing is what is to the right of this image.\n",
    "\n",
    "![My old Eclipse!](Images/nodes_tags_value_basketball_visual_2.JPG)\n",
    "\n",
    "My first car was a [GST 1996 Eclipse](https://www.google.com/search?q=eclipse+1996+gst&tbm=isch&imgil=AEDs13ALw6VeOM%253A%253ByMkrvx2fFtnpMM%253Bhttps%25253A%25252F%25252Fwww.tamparacing.com%25252Fforums%25252Fcars-sale-wanted%25252F725393-ft-fs-1996-mitsu-eclipse-gst-great-deal.html&source=iu&pf=m&fir=AEDs13ALw6VeOM%253A%252CyMkrvx2fFtnpMM%252C_&usg=___G1bsG0XKmgG9d1ti9hilZVdIMs%3D&biw=1286&bih=702&ved=0ahUKEwjq07_YzbvUAhUU0GMKHQ7TAl4QyjcIkwE&ei=1UNAWaqVHJSgjwOOpovwBQ#imgrc=AEDs13ALw6VeOM:). Unfortunately, I couldn't handle it's power and finance re-occuring repairs. \n",
    "\n",
    "I sold it to someone for $\\$ 500-\\$ 600 $ because it was in a pretty bad condition. This person flipped the Eclipse to what you see above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Recommendations**\n",
    "We observed the sparse osm file southmodesto.osm needed to be audited before fully importing and creating a database off of it. Integrity in our data should be the overall theme for this and several other datasets.\n",
    "\n",
    "To either avoid mishaps of entered data, here are some recommendations:\n",
    "\n",
    "- Create a input guideline for users.\n",
    "- Set conditions on entry boxes to avoid incorrect submissions \n",
    "- Inputing missing values from other values within the same node.\n",
    "- Using third party data  to cross validate and improve the dataset.\n",
    "- Create a preliminary warning \"Are you sure this is the correct input\" before final submission\n",
    "\n",
    "With these ideas being implemented, we provide additional ease in importing and transforming data. I.e., With these above conditions being implemented, the data analyst's dirty work(data wrangle) becomes more tolerable. \n",
    "\n",
    "<span style = \"color:purple\"> **Note:**\n",
    "If administrators continue data wrangling procedures without the implementation of the above recommendations, the administrator needs to ensure that the data cleaning does not create data loss of important user entries </span>\n",
    "\n",
    "**Consequences**\n",
    "\n",
    "The potential problems of implementing these solutions is user satisfaction of using services. If a user keeps on receiving notifications or warnings in submission process, the likelyhood of the user using are services diminishes.\n",
    "\n",
    "We can solve these potential problems when implementing the above solutions by providing examples along the entry locations. \n",
    "In putting in your birth in an online application, there usually is a provided example of how to enter your birthdate like so:\n",
    "\n",
    "[___ENTER HERE____] <span style=\"color:red\">(Ex. MM/DD/YYYY)</span>\n",
    "\n",
    "User instructions with our recommended solutions provide a balance between user actions and administrative needs. Therefore, the likelyhood of a diminished retention rate would not change significantly.\n",
    "\n",
    "\n",
    "With these above ideas being implemented, we provide a more sound import process of our data into our required data format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
